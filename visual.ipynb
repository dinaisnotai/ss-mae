{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T17:20:54.765888Z",
     "start_time": "2025-01-20T17:17:04.199242Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from net.VIT.mae import VisionTransfromers as MAEFinetune\n",
    "from get_dat import get_dataset\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "def visualize_predictions(args, model, all_loader):\n",
    "    \"\"\"\n",
    "    对所有点进行预测并可视化结果\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    predictions = []  # 存储预测结果\n",
    "    # ground_truth = []  # 存储真实标签（如果有）\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (hsi, lidar, labels, hsi_pca) in enumerate(all_loader):\n",
    "            hsi = hsi.to(device)\n",
    "            lidar = lidar.to(device)\n",
    "            hsi_pca = hsi_pca.to(device)\n",
    "\n",
    "            # 进行预测\n",
    "            outputs, _ = model(hsi, lidar, hsi_pca)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()  # 获取预测类别\n",
    "            predictions.extend(preds)\n",
    "\n",
    "            # 如果有真实标签，可以保存用于对比\n",
    "            # if labels is not None:\n",
    "            #     ground_truth.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 将预测结果转换为图像格式\n",
    "    predictions = np.array(predictions)\n",
    "    # if len(ground_truth) > 0:\n",
    "    #     ground_truth = np.array(ground_truth)\n",
    "\n",
    "    # 获取原始数据的形状（假设数据是二维的）\n",
    "    hsi_path = \"data/tlse/processed_hsi.h5\"  # 替换为你的数据路径\n",
    "    with h5py.File(hsi_path, 'r') as h5_file:\n",
    "        hsi_data = h5_file['hyperspectral_matrix'][:] \n",
    "    height, width, _ = hsi_data.shape\n",
    "\n",
    "    # 将预测结果重塑为原始图像形状\n",
    "    pred_image = np.zeros((height, width), dtype=np.uint8)\n",
    "    # gt_image = np.zeros((height, width), dtype=np.uint8) if len(ground_truth) > 0 else None\n",
    "\n",
    "    # 填充预测结果\n",
    "    all_index = loadmat(\"data/tlse/tlse_index.mat\")['tlse_all']  # 替换为你的索引路径\n",
    "    for idx, (h, w) in enumerate(all_index):\n",
    "        pred_image[h, w] = predictions[idx] + 1  # 类别从0开始，+1是为了与真实标签对齐\n",
    "        # if gt_image is not None:\n",
    "        #     gt_image[h, w] = ground_truth[idx]\n",
    "\n",
    "    # 可视化预测结果\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 绘制预测结果\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(pred_image, cmap='jet')\n",
    "    plt.title(\"Predicted Labels\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # # 如果有真实标签，绘制真实标签\n",
    "    # if gt_image is not None:\n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     plt.imshow(gt_image, cmap='jet')\n",
    "    #     plt.title(\"Ground Truth\")\n",
    "    #     plt.colorbar()\n",
    "    # \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "# 在主函数中调用可视化函数\n",
    "if __name__ == '__main__':\n",
    "    # 加载最佳模型\n",
    "    class Args:\n",
    "        is_train = 0\n",
    "        is_load_pretrain = 0\n",
    "        is_pretrain = 1\n",
    "        is_test = 0\n",
    "        model_file = 'model'\n",
    "        size_SA = 49\n",
    "        channel_number = 291\n",
    "        epoch = 500\n",
    "        pca_num = 30\n",
    "        mask_ratio = 0.7\n",
    "        crop_size = 7\n",
    "        device = \"cuda:0\"\n",
    "        dataset = 'Tlse'\n",
    "        num_classes = 13\n",
    "        pretrain_num = 400000\n",
    "        patch_size = 1\n",
    "        finetune = 0\n",
    "        mae_pretrain = 1\n",
    "        depth = 2\n",
    "        head = 8\n",
    "        dim = 256\n",
    "        model_name = None\n",
    "        warmup_epochs = 5\n",
    "        test_interval = 5\n",
    "        optimizer_name = \"adamw\"\n",
    "        lr = 1e-4\n",
    "        cosine = 0\n",
    "        weight_decay = 5e-2\n",
    "        batch_size = 256\n",
    "\n",
    "    args = Args()\n",
    "    \n",
    "    model = MAEFinetune(\n",
    "    channel_number=args.channel_number,\n",
    "    img_size=args.crop_size,\n",
    "    patch_size=args.patch_size,\n",
    "    embed_dim=args.dim,\n",
    "    depth=args.depth,\n",
    "    num_heads=args.head,\n",
    "    num_classes=args.num_classes,\n",
    "    args=args\n",
    "    )\n",
    "    \n",
    "    device='cuda'\n",
    "    save_dir = os.path.join('model', 'train', '20250120_235027')\n",
    "    model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "    checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.cuda(device=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    \n",
    "    pretrain_loader, train_loader, test_loader, trntst_loader, all_loader = get_dataset(args)\n",
    "    \n",
    "    # 调用可视化函数\n",
    "    visualize_predictions(args, model, all_loader)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\temp\\ipykernel_25660\\3580014077.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tlse!\n",
      "(3800, 1440)\n",
      "(3800, 1440, 290)\n",
      "HSI shape: torch.Size([3800, 1440, 290])\n",
      "LiDAR shape: torch.Size([3800, 1440])\n",
      "Labels shape: torch.Size([1, 3800, 1440])\n",
      "Labels shape: torch.Size([3800, 1440])\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.95 GiB for an array with shape (3806, 1446, 290) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 131\u001B[0m\n\u001B[0;32m    126\u001B[0m model\u001B[38;5;241m.\u001B[39mcuda(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m    128\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 131\u001B[0m pretrain_loader, train_loader, test_loader, trntst_loader, all_loader \u001B[38;5;241m=\u001B[39m \u001B[43mget_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;66;03m# 调用可视化函数\u001B[39;00m\n\u001B[0;32m    134\u001B[0m visualize_predictions(args, model, all_loader)\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\SS-MAE\\get_dat.py:35\u001B[0m, in \u001B[0;36mget_dataset\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m     27\u001B[0m     pretrain_loader, train_loader, test_loader, trntst_loader, all_loader \u001B[38;5;241m=\u001B[39m Dataset\u001B[38;5;241m.\u001B[39mgetHSData(\n\u001B[0;32m     28\u001B[0m         datasetType\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAugsburg\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     29\u001B[0m         channels\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mpca_num,\n\u001B[0;32m     30\u001B[0m         windowSize\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mcrop_size,\n\u001B[0;32m     31\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mbatch_size,\n\u001B[0;32m     32\u001B[0m         num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,args\u001B[38;5;241m=\u001B[39margs)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m train_dataset \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTlse\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 35\u001B[0m     pretrain_loader, train_loader, test_loader, trntst_loader, all_loader \u001B[38;5;241m=\u001B[39m \u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetHSData\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdatasetType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTlse\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpca_num\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwindowSize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrop_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pretrain_loader, train_loader, test_loader, trntst_loader, all_loader\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\SS-MAE\\data\\dataset.py:427\u001B[0m, in \u001B[0;36mgetHSData\u001B[1;34m(datasetType, channels, windowSize, batch_size, num_workers, args)\u001B[0m\n\u001B[0;32m    425\u001B[0m     gt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/tlse/processed_gt.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    426\u001B[0m     index_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/tlse/tlse_index.mat\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 427\u001B[0m     pretrain_loader, train_loader, test_loader, trntst_loader, all_loader \u001B[38;5;241m=\u001B[39m \u001B[43mgetTlseData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhsi_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlidar_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m                                                                                               \u001B[49m\u001B[43mgt_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m                                                                                               \u001B[49m\u001B[43mindex_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m                                                                                               \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindowSize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m                                                                                               \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m                                                                                               \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pretrain_loader, train_loader, test_loader, trntst_loader, all_loader\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\SS-MAE\\data\\dataset.py:390\u001B[0m, in \u001B[0;36mgetTlseData\u001B[1;34m(hsi_path, lidar_path, gt_path, index_path, channels, windowSize, batch_size, num_workers, args)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;66;03m# Houston2018 mat keys\u001B[39;00m\n\u001B[0;32m    388\u001B[0m Tlse_keys \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_hsi\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_lidar\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_gt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_train\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_test\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_all\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgetData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhsi_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlidar_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTlse_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindowSize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m               \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\SS-MAE\\data\\dataset.py:326\u001B[0m, in \u001B[0;36mgetData\u001B[1;34m(hsi_path, X_path, gt_path, index_path, keys, channels, windowSize, batch_size, num_workers, args)\u001B[0m\n\u001B[0;32m    322\u001B[0m     pretrain_loader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m    323\u001B[0m         HXpretrainset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39mnum_workers, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(keys\u001B[38;5;241m==\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_hsi\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_lidar\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_gt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_train\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_test\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtlse_all\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m--> 326\u001B[0m     train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCustomDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhsi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhsi_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    327\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mwindowSize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    328\u001B[0m     test_dataset \u001B[38;5;241m=\u001B[39m CustomDataset(hsi, hsi_pca, X, test_index,\n\u001B[0;32m    329\u001B[0m                           windowSize, gt, transform\u001B[38;5;241m=\u001B[39mToTensor())\n\u001B[0;32m    330\u001B[0m     trntst_dataset \u001B[38;5;241m=\u001B[39m CustomDataset(hsi, hsi_pca, X, trntst_index,\n\u001B[0;32m    331\u001B[0m                             windowSize, gt, transform\u001B[38;5;241m=\u001B[39mToTensor())\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\SS-MAE\\data\\dataset.py:167\u001B[0m, in \u001B[0;36mCustomDataset.__init__\u001B[1;34m(self, hsi, hsi_pca, lidar, pos, windowSize, labels, transform, train)\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindowSize \u001B[38;5;241m=\u001B[39m windowSize\n\u001B[0;32m    166\u001B[0m modes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msymmetric\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreflect\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 167\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhsi \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhsi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mwindowSize\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhsi_pca \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpad(hsi_pca, ((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad), (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad), (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m)), mode\u001B[38;5;241m=\u001B[39mmodes[windowSize \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lidar\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\tlse-experiments\\venv\\lib\\site-packages\\numpy\\lib\\arraypad.py:798\u001B[0m, in \u001B[0;36mpad\u001B[1;34m(array, pad_width, mode, **kwargs)\u001B[0m\n\u001B[0;32m    793\u001B[0m stat_functions \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximum\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mamax, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mminimum\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mamin,\n\u001B[0;32m    794\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mmean, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mmedian}\n\u001B[0;32m    796\u001B[0m \u001B[38;5;66;03m# Create array with final shape and original values\u001B[39;00m\n\u001B[0;32m    797\u001B[0m \u001B[38;5;66;03m# (padded area is undefined)\u001B[39;00m\n\u001B[1;32m--> 798\u001B[0m padded, original_area_slice \u001B[38;5;241m=\u001B[39m \u001B[43m_pad_simple\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_width\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[38;5;66;03m# And prepare iteration over all dimensions\u001B[39;00m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;66;03m# (zipping may be more readable than using enumerate)\u001B[39;00m\n\u001B[0;32m    801\u001B[0m axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(padded\u001B[38;5;241m.\u001B[39mndim)\n",
      "File \u001B[1;32mD:\\dina-zhang\\学习\\大创\\tlse-experiments\\venv\\lib\\site-packages\\numpy\\lib\\arraypad.py:114\u001B[0m, in \u001B[0;36m_pad_simple\u001B[1;34m(array, pad_width, fill_value)\u001B[0m\n\u001B[0;32m    109\u001B[0m new_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[0;32m    110\u001B[0m     left \u001B[38;5;241m+\u001B[39m size \u001B[38;5;241m+\u001B[39m right\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m size, (left, right) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(array\u001B[38;5;241m.\u001B[39mshape, pad_width)\n\u001B[0;32m    112\u001B[0m )\n\u001B[0;32m    113\u001B[0m order \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mfnc \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Fortran and not also C-order\u001B[39;00m\n\u001B[1;32m--> 114\u001B[0m padded \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fill_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    117\u001B[0m     padded\u001B[38;5;241m.\u001B[39mfill(fill_value)\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 5.95 GiB for an array with shape (3806, 1446, 290) and data type float32"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a5c6efcff1fd017"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
